{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU keras pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((img_width, img_height)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Directories for training and validation data\n",
    "train_data_dir = 'C:\\\\Users\\\\Cody\\\\Desktop\\\\Projects\\\\Mr-Beans\\\\notebook\\\\exploration\\\\beans\\\\data\\\\type\\\\train'\n",
    "validation_data_dir = 'C:\\\\Users\\\\Cody\\\\Desktop\\\\Projects\\\\Mr-Beans\\\\notebook\\\\exploration\\\\beans\\\\data\\\\type\\\\test'\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = datasets.ImageFolder(train_data_dir, transform=data_transforms['train'])\n",
    "validation_dataset = datasets.ImageFolder(validation_data_dir, transform=data_transforms['validation'])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Additional pooling to further reduce dimensionality\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Calculate the new size after pooling\n",
    "        self.fc1 = nn.Linear(128 * 14 * 14, 512)  # Reduced size from additional pooling (14x14)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, len(train_dataset.classes))  # Adjust based on number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv3(x)))\n",
    "        x = self.pool2(x)  # Additional pooling layer for reducing dimensions\n",
    "        x = x.view(-1, 128 * 14 * 14)  # Adjust for the reduced spatial dimensions\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNNModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 1.3843\n",
      "Batch 11/400 - Loss: 1.3640\n",
      "Batch 21/400 - Loss: 1.3846\n",
      "Batch 31/400 - Loss: 1.3922\n",
      "Batch 41/400 - Loss: 1.4095\n",
      "Batch 51/400 - Loss: 1.3639\n",
      "Batch 61/400 - Loss: 1.3694\n",
      "Batch 71/400 - Loss: 1.3981\n",
      "Batch 81/400 - Loss: 1.3653\n",
      "Batch 91/400 - Loss: 1.2281\n",
      "Batch 101/400 - Loss: 1.1967\n",
      "Batch 111/400 - Loss: 1.1556\n",
      "Batch 121/400 - Loss: 1.2281\n",
      "Batch 131/400 - Loss: 1.1747\n",
      "Batch 141/400 - Loss: 1.3018\n",
      "Batch 151/400 - Loss: 1.1646\n",
      "Batch 161/400 - Loss: 1.0645\n",
      "Batch 171/400 - Loss: 0.9298\n",
      "Batch 181/400 - Loss: 1.5990\n",
      "Batch 191/400 - Loss: 1.0972\n",
      "Batch 201/400 - Loss: 1.2398\n",
      "Batch 211/400 - Loss: 1.1779\n",
      "Batch 221/400 - Loss: 1.3281\n",
      "Batch 231/400 - Loss: 1.0672\n",
      "Batch 241/400 - Loss: 1.1151\n",
      "Batch 251/400 - Loss: 0.9420\n",
      "Batch 261/400 - Loss: 1.2500\n",
      "Batch 271/400 - Loss: 1.1356\n",
      "Batch 281/400 - Loss: 1.0284\n",
      "Batch 291/400 - Loss: 1.0334\n",
      "Batch 301/400 - Loss: 0.7760\n",
      "Batch 311/400 - Loss: 0.8962\n",
      "Batch 321/400 - Loss: 1.0595\n",
      "Batch 331/400 - Loss: 1.2188\n",
      "Batch 341/400 - Loss: 0.7360\n",
      "Batch 351/400 - Loss: 0.8015\n",
      "Batch 361/400 - Loss: 0.9206\n",
      "Batch 371/400 - Loss: 1.1995\n",
      "Batch 381/400 - Loss: 0.8619\n",
      "Batch 391/400 - Loss: 0.9247\n",
      "Epoch [1/10], Loss: 1.1543\n",
      "Validation Batch 1/100 - Loss: 1.3251\n",
      "Validation Batch 6/100 - Loss: 1.2891\n",
      "Validation Batch 11/100 - Loss: 1.1908\n",
      "Validation Batch 16/100 - Loss: 1.4541\n",
      "Validation Batch 21/100 - Loss: 1.2869\n",
      "Validation Batch 26/100 - Loss: 0.4806\n",
      "Validation Batch 31/100 - Loss: 0.2060\n",
      "Validation Batch 36/100 - Loss: 0.8580\n",
      "Validation Batch 41/100 - Loss: 0.7131\n",
      "Validation Batch 46/100 - Loss: 0.2689\n",
      "Validation Batch 51/100 - Loss: 1.0915\n",
      "Validation Batch 56/100 - Loss: 1.4757\n",
      "Validation Batch 61/100 - Loss: 0.8822\n",
      "Validation Batch 66/100 - Loss: 0.7318\n",
      "Validation Batch 71/100 - Loss: 0.9486\n",
      "Validation Batch 76/100 - Loss: 0.9476\n",
      "Validation Batch 81/100 - Loss: 0.7813\n",
      "Validation Batch 86/100 - Loss: 0.8749\n",
      "Validation Batch 91/100 - Loss: 0.8360\n",
      "Validation Batch 96/100 - Loss: 0.9891\n",
      "Validation Loss: 0.8987, Validation Accuracy: 62.88%\n",
      "Epoch 2/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.9602\n",
      "Batch 11/400 - Loss: 1.2532\n",
      "Batch 21/400 - Loss: 0.6232\n",
      "Batch 31/400 - Loss: 1.2391\n",
      "Batch 41/400 - Loss: 0.9580\n",
      "Batch 51/400 - Loss: 1.1715\n",
      "Batch 61/400 - Loss: 0.8792\n",
      "Batch 71/400 - Loss: 0.9302\n",
      "Batch 81/400 - Loss: 0.8683\n",
      "Batch 91/400 - Loss: 0.5831\n",
      "Batch 101/400 - Loss: 0.7333\n",
      "Batch 111/400 - Loss: 1.2550\n",
      "Batch 121/400 - Loss: 0.5686\n",
      "Batch 131/400 - Loss: 0.9216\n",
      "Batch 141/400 - Loss: 0.7349\n",
      "Batch 151/400 - Loss: 0.8673\n",
      "Batch 161/400 - Loss: 0.6665\n",
      "Batch 171/400 - Loss: 1.0223\n",
      "Batch 181/400 - Loss: 0.6954\n",
      "Batch 191/400 - Loss: 0.9782\n",
      "Batch 201/400 - Loss: 1.1262\n",
      "Batch 211/400 - Loss: 0.7958\n",
      "Batch 221/400 - Loss: 0.6111\n",
      "Batch 231/400 - Loss: 0.7570\n",
      "Batch 241/400 - Loss: 0.7668\n",
      "Batch 251/400 - Loss: 0.9070\n",
      "Batch 261/400 - Loss: 0.4596\n",
      "Batch 271/400 - Loss: 0.7875\n",
      "Batch 281/400 - Loss: 0.8005\n",
      "Batch 291/400 - Loss: 0.8226\n",
      "Batch 301/400 - Loss: 0.7189\n",
      "Batch 311/400 - Loss: 0.6908\n",
      "Batch 321/400 - Loss: 1.0664\n",
      "Batch 331/400 - Loss: 0.6546\n",
      "Batch 341/400 - Loss: 1.0793\n",
      "Batch 351/400 - Loss: 1.4429\n",
      "Batch 361/400 - Loss: 0.6460\n",
      "Batch 371/400 - Loss: 0.7528\n",
      "Batch 381/400 - Loss: 0.7616\n",
      "Batch 391/400 - Loss: 0.6727\n",
      "Epoch [2/10], Loss: 0.8452\n",
      "Validation Batch 1/100 - Loss: 0.8276\n",
      "Validation Batch 6/100 - Loss: 0.7145\n",
      "Validation Batch 11/100 - Loss: 0.8386\n",
      "Validation Batch 16/100 - Loss: 1.0496\n",
      "Validation Batch 21/100 - Loss: 0.5183\n",
      "Validation Batch 26/100 - Loss: 0.3756\n",
      "Validation Batch 31/100 - Loss: 0.0996\n",
      "Validation Batch 36/100 - Loss: 0.7437\n",
      "Validation Batch 41/100 - Loss: 0.7506\n",
      "Validation Batch 46/100 - Loss: 0.1243\n",
      "Validation Batch 51/100 - Loss: 1.0753\n",
      "Validation Batch 56/100 - Loss: 1.2376\n",
      "Validation Batch 61/100 - Loss: 0.7578\n",
      "Validation Batch 66/100 - Loss: 0.5751\n",
      "Validation Batch 71/100 - Loss: 0.8921\n",
      "Validation Batch 76/100 - Loss: 1.1657\n",
      "Validation Batch 81/100 - Loss: 1.1234\n",
      "Validation Batch 86/100 - Loss: 0.9797\n",
      "Validation Batch 91/100 - Loss: 0.9096\n",
      "Validation Batch 96/100 - Loss: 1.2863\n",
      "Validation Loss: 0.7826, Validation Accuracy: 67.44%\n",
      "Epoch 3/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.8836\n",
      "Batch 11/400 - Loss: 0.9565\n",
      "Batch 21/400 - Loss: 0.5998\n",
      "Batch 31/400 - Loss: 0.8854\n",
      "Batch 41/400 - Loss: 1.0253\n",
      "Batch 51/400 - Loss: 0.7272\n",
      "Batch 61/400 - Loss: 0.4867\n",
      "Batch 71/400 - Loss: 1.1095\n",
      "Batch 81/400 - Loss: 0.7150\n",
      "Batch 91/400 - Loss: 0.7471\n",
      "Batch 101/400 - Loss: 0.6020\n",
      "Batch 111/400 - Loss: 0.5520\n",
      "Batch 121/400 - Loss: 0.6737\n",
      "Batch 131/400 - Loss: 0.9509\n",
      "Batch 141/400 - Loss: 0.5787\n",
      "Batch 151/400 - Loss: 0.7136\n",
      "Batch 161/400 - Loss: 0.7726\n",
      "Batch 171/400 - Loss: 0.7646\n",
      "Batch 181/400 - Loss: 0.6344\n",
      "Batch 191/400 - Loss: 0.6885\n",
      "Batch 201/400 - Loss: 0.8325\n",
      "Batch 211/400 - Loss: 0.9811\n",
      "Batch 221/400 - Loss: 0.4946\n",
      "Batch 231/400 - Loss: 0.6799\n",
      "Batch 241/400 - Loss: 0.8785\n",
      "Batch 251/400 - Loss: 0.3889\n",
      "Batch 261/400 - Loss: 0.5921\n",
      "Batch 271/400 - Loss: 0.8118\n",
      "Batch 281/400 - Loss: 0.7542\n",
      "Batch 291/400 - Loss: 0.6639\n",
      "Batch 301/400 - Loss: 0.5273\n",
      "Batch 311/400 - Loss: 0.6113\n",
      "Batch 321/400 - Loss: 0.8365\n",
      "Batch 331/400 - Loss: 0.6602\n",
      "Batch 341/400 - Loss: 0.7135\n",
      "Batch 351/400 - Loss: 0.7582\n",
      "Batch 361/400 - Loss: 0.4844\n",
      "Batch 371/400 - Loss: 0.7925\n",
      "Batch 381/400 - Loss: 0.5687\n",
      "Batch 391/400 - Loss: 0.6194\n",
      "Epoch [3/10], Loss: 0.7359\n",
      "Validation Batch 1/100 - Loss: 0.7955\n",
      "Validation Batch 6/100 - Loss: 0.6819\n",
      "Validation Batch 11/100 - Loss: 0.8885\n",
      "Validation Batch 16/100 - Loss: 1.1455\n",
      "Validation Batch 21/100 - Loss: 0.3655\n",
      "Validation Batch 26/100 - Loss: 0.3294\n",
      "Validation Batch 31/100 - Loss: 0.0579\n",
      "Validation Batch 36/100 - Loss: 0.2660\n",
      "Validation Batch 41/100 - Loss: 0.5576\n",
      "Validation Batch 46/100 - Loss: 0.1271\n",
      "Validation Batch 51/100 - Loss: 1.2280\n",
      "Validation Batch 56/100 - Loss: 1.7492\n",
      "Validation Batch 61/100 - Loss: 0.9813\n",
      "Validation Batch 66/100 - Loss: 0.8259\n",
      "Validation Batch 71/100 - Loss: 1.1869\n",
      "Validation Batch 76/100 - Loss: 0.6517\n",
      "Validation Batch 81/100 - Loss: 0.8576\n",
      "Validation Batch 86/100 - Loss: 0.8767\n",
      "Validation Batch 91/100 - Loss: 0.8891\n",
      "Validation Batch 96/100 - Loss: 1.3767\n",
      "Validation Loss: 0.7547, Validation Accuracy: 69.44%\n",
      "Epoch 4/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.7623\n",
      "Batch 11/400 - Loss: 0.7637\n",
      "Batch 21/400 - Loss: 0.5928\n",
      "Batch 31/400 - Loss: 0.6602\n",
      "Batch 41/400 - Loss: 0.7887\n",
      "Batch 51/400 - Loss: 0.6466\n",
      "Batch 61/400 - Loss: 0.9403\n",
      "Batch 71/400 - Loss: 0.5685\n",
      "Batch 81/400 - Loss: 1.0807\n",
      "Batch 91/400 - Loss: 0.6219\n",
      "Batch 101/400 - Loss: 0.8985\n",
      "Batch 111/400 - Loss: 1.1276\n",
      "Batch 121/400 - Loss: 0.8853\n",
      "Batch 131/400 - Loss: 0.6771\n",
      "Batch 141/400 - Loss: 0.7448\n",
      "Batch 151/400 - Loss: 1.4443\n",
      "Batch 161/400 - Loss: 0.4485\n",
      "Batch 171/400 - Loss: 0.4656\n",
      "Batch 181/400 - Loss: 1.0058\n",
      "Batch 191/400 - Loss: 0.6556\n",
      "Batch 201/400 - Loss: 0.4612\n",
      "Batch 211/400 - Loss: 0.8128\n",
      "Batch 221/400 - Loss: 0.7017\n",
      "Batch 231/400 - Loss: 0.7242\n",
      "Batch 241/400 - Loss: 0.5227\n",
      "Batch 251/400 - Loss: 0.9739\n",
      "Batch 261/400 - Loss: 0.7905\n",
      "Batch 271/400 - Loss: 0.4760\n",
      "Batch 281/400 - Loss: 0.7071\n",
      "Batch 291/400 - Loss: 0.8377\n",
      "Batch 301/400 - Loss: 0.6595\n",
      "Batch 311/400 - Loss: 0.5742\n",
      "Batch 321/400 - Loss: 0.4357\n",
      "Batch 331/400 - Loss: 0.8974\n",
      "Batch 341/400 - Loss: 0.1679\n",
      "Batch 351/400 - Loss: 0.5928\n",
      "Batch 361/400 - Loss: 0.8966\n",
      "Batch 371/400 - Loss: 0.4144\n",
      "Batch 381/400 - Loss: 0.7895\n",
      "Batch 391/400 - Loss: 0.7851\n",
      "Epoch [4/10], Loss: 0.6710\n",
      "Validation Batch 1/100 - Loss: 1.0728\n",
      "Validation Batch 6/100 - Loss: 1.1713\n",
      "Validation Batch 11/100 - Loss: 1.0405\n",
      "Validation Batch 16/100 - Loss: 1.3506\n",
      "Validation Batch 21/100 - Loss: 0.5573\n",
      "Validation Batch 26/100 - Loss: 0.3512\n",
      "Validation Batch 31/100 - Loss: 0.1351\n",
      "Validation Batch 36/100 - Loss: 0.7163\n",
      "Validation Batch 41/100 - Loss: 0.6266\n",
      "Validation Batch 46/100 - Loss: 0.1489\n",
      "Validation Batch 51/100 - Loss: 0.6834\n",
      "Validation Batch 56/100 - Loss: 1.0397\n",
      "Validation Batch 61/100 - Loss: 0.6128\n",
      "Validation Batch 66/100 - Loss: 0.2599\n",
      "Validation Batch 71/100 - Loss: 0.3567\n",
      "Validation Batch 76/100 - Loss: 1.2199\n",
      "Validation Batch 81/100 - Loss: 0.8121\n",
      "Validation Batch 86/100 - Loss: 0.7395\n",
      "Validation Batch 91/100 - Loss: 0.7310\n",
      "Validation Batch 96/100 - Loss: 1.1142\n",
      "Validation Loss: 0.6820, Validation Accuracy: 74.19%\n",
      "Epoch 5/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.5998\n",
      "Batch 11/400 - Loss: 0.8214\n",
      "Batch 21/400 - Loss: 0.8457\n",
      "Batch 31/400 - Loss: 0.4916\n",
      "Batch 41/400 - Loss: 0.3837\n",
      "Batch 51/400 - Loss: 0.7803\n",
      "Batch 61/400 - Loss: 0.5667\n",
      "Batch 71/400 - Loss: 0.4756\n",
      "Batch 81/400 - Loss: 0.7909\n",
      "Batch 91/400 - Loss: 0.9539\n",
      "Batch 101/400 - Loss: 0.8414\n",
      "Batch 111/400 - Loss: 0.8888\n",
      "Batch 121/400 - Loss: 0.5567\n",
      "Batch 131/400 - Loss: 0.4466\n",
      "Batch 141/400 - Loss: 0.7864\n",
      "Batch 151/400 - Loss: 0.6408\n",
      "Batch 161/400 - Loss: 0.7503\n",
      "Batch 171/400 - Loss: 0.4141\n",
      "Batch 181/400 - Loss: 0.4214\n",
      "Batch 191/400 - Loss: 0.6882\n",
      "Batch 201/400 - Loss: 0.3612\n",
      "Batch 211/400 - Loss: 0.6163\n",
      "Batch 221/400 - Loss: 0.9089\n",
      "Batch 231/400 - Loss: 0.7709\n",
      "Batch 241/400 - Loss: 1.4765\n",
      "Batch 251/400 - Loss: 0.5213\n",
      "Batch 261/400 - Loss: 0.4432\n",
      "Batch 271/400 - Loss: 0.6304\n",
      "Batch 281/400 - Loss: 0.6426\n",
      "Batch 291/400 - Loss: 0.5190\n",
      "Batch 301/400 - Loss: 0.4072\n",
      "Batch 311/400 - Loss: 0.4514\n",
      "Batch 321/400 - Loss: 0.4867\n",
      "Batch 331/400 - Loss: 0.6733\n",
      "Batch 341/400 - Loss: 0.6557\n",
      "Batch 351/400 - Loss: 0.9373\n",
      "Batch 361/400 - Loss: 0.5828\n",
      "Batch 371/400 - Loss: 0.3083\n",
      "Batch 381/400 - Loss: 0.7810\n",
      "Batch 391/400 - Loss: 0.6191\n",
      "Epoch [5/10], Loss: 0.6287\n",
      "Validation Batch 1/100 - Loss: 1.0907\n",
      "Validation Batch 6/100 - Loss: 1.3887\n",
      "Validation Batch 11/100 - Loss: 1.2818\n",
      "Validation Batch 16/100 - Loss: 1.4605\n",
      "Validation Batch 21/100 - Loss: 0.5874\n",
      "Validation Batch 26/100 - Loss: 0.3114\n",
      "Validation Batch 31/100 - Loss: 0.0811\n",
      "Validation Batch 36/100 - Loss: 0.4041\n",
      "Validation Batch 41/100 - Loss: 0.5463\n",
      "Validation Batch 46/100 - Loss: 0.1034\n",
      "Validation Batch 51/100 - Loss: 0.8266\n",
      "Validation Batch 56/100 - Loss: 1.0962\n",
      "Validation Batch 61/100 - Loss: 0.6115\n",
      "Validation Batch 66/100 - Loss: 0.3834\n",
      "Validation Batch 71/100 - Loss: 0.5227\n",
      "Validation Batch 76/100 - Loss: 0.5443\n",
      "Validation Batch 81/100 - Loss: 0.6645\n",
      "Validation Batch 86/100 - Loss: 0.4402\n",
      "Validation Batch 91/100 - Loss: 0.4944\n",
      "Validation Batch 96/100 - Loss: 0.7988\n",
      "Validation Loss: 0.6575, Validation Accuracy: 75.38%\n",
      "Epoch 6/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.4346\n",
      "Batch 11/400 - Loss: 0.4342\n",
      "Batch 21/400 - Loss: 0.7684\n",
      "Batch 31/400 - Loss: 0.7365\n",
      "Batch 41/400 - Loss: 0.7987\n",
      "Batch 51/400 - Loss: 0.5979\n",
      "Batch 61/400 - Loss: 0.9031\n",
      "Batch 71/400 - Loss: 0.6168\n",
      "Batch 81/400 - Loss: 0.5636\n",
      "Batch 91/400 - Loss: 0.4789\n",
      "Batch 101/400 - Loss: 0.4424\n",
      "Batch 111/400 - Loss: 0.7686\n",
      "Batch 121/400 - Loss: 0.8069\n",
      "Batch 131/400 - Loss: 0.6082\n",
      "Batch 141/400 - Loss: 0.6532\n",
      "Batch 151/400 - Loss: 0.3242\n",
      "Batch 161/400 - Loss: 0.8409\n",
      "Batch 171/400 - Loss: 0.3965\n",
      "Batch 181/400 - Loss: 0.5367\n",
      "Batch 191/400 - Loss: 0.9451\n",
      "Batch 201/400 - Loss: 0.4017\n",
      "Batch 211/400 - Loss: 0.5492\n",
      "Batch 221/400 - Loss: 0.7660\n",
      "Batch 231/400 - Loss: 0.2847\n",
      "Batch 241/400 - Loss: 0.7896\n",
      "Batch 251/400 - Loss: 0.4477\n",
      "Batch 261/400 - Loss: 0.2376\n",
      "Batch 271/400 - Loss: 1.2237\n",
      "Batch 281/400 - Loss: 0.5301\n",
      "Batch 291/400 - Loss: 0.8676\n",
      "Batch 301/400 - Loss: 1.0416\n",
      "Batch 311/400 - Loss: 0.5122\n",
      "Batch 321/400 - Loss: 0.9861\n",
      "Batch 331/400 - Loss: 0.5395\n",
      "Batch 341/400 - Loss: 0.6809\n",
      "Batch 351/400 - Loss: 0.5120\n",
      "Batch 361/400 - Loss: 0.4377\n",
      "Batch 371/400 - Loss: 1.0761\n",
      "Batch 381/400 - Loss: 0.2282\n",
      "Batch 391/400 - Loss: 0.4297\n",
      "Epoch [6/10], Loss: 0.5916\n",
      "Validation Batch 1/100 - Loss: 0.5845\n",
      "Validation Batch 6/100 - Loss: 0.6524\n",
      "Validation Batch 11/100 - Loss: 0.7368\n",
      "Validation Batch 16/100 - Loss: 1.0731\n",
      "Validation Batch 21/100 - Loss: 0.3827\n",
      "Validation Batch 26/100 - Loss: 0.3359\n",
      "Validation Batch 31/100 - Loss: 0.0810\n",
      "Validation Batch 36/100 - Loss: 0.5531\n",
      "Validation Batch 41/100 - Loss: 0.6338\n",
      "Validation Batch 46/100 - Loss: 0.0647\n",
      "Validation Batch 51/100 - Loss: 0.7133\n",
      "Validation Batch 56/100 - Loss: 0.8222\n",
      "Validation Batch 61/100 - Loss: 0.5071\n",
      "Validation Batch 66/100 - Loss: 0.3543\n",
      "Validation Batch 71/100 - Loss: 0.5032\n",
      "Validation Batch 76/100 - Loss: 0.8332\n",
      "Validation Batch 81/100 - Loss: 0.8496\n",
      "Validation Batch 86/100 - Loss: 0.6403\n",
      "Validation Batch 91/100 - Loss: 0.7532\n",
      "Validation Batch 96/100 - Loss: 1.1392\n",
      "Validation Loss: 0.5981, Validation Accuracy: 77.44%\n",
      "Epoch 7/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.5069\n",
      "Batch 11/400 - Loss: 0.4634\n",
      "Batch 21/400 - Loss: 0.4420\n",
      "Batch 31/400 - Loss: 0.3757\n",
      "Batch 41/400 - Loss: 0.3153\n",
      "Batch 51/400 - Loss: 0.3784\n",
      "Batch 61/400 - Loss: 0.6402\n",
      "Batch 71/400 - Loss: 0.6789\n",
      "Batch 81/400 - Loss: 1.1540\n",
      "Batch 91/400 - Loss: 0.8528\n",
      "Batch 101/400 - Loss: 0.8430\n",
      "Batch 111/400 - Loss: 0.4031\n",
      "Batch 121/400 - Loss: 0.2723\n",
      "Batch 131/400 - Loss: 0.3213\n",
      "Batch 141/400 - Loss: 0.1970\n",
      "Batch 151/400 - Loss: 0.4568\n",
      "Batch 161/400 - Loss: 1.0048\n",
      "Batch 171/400 - Loss: 0.6127\n",
      "Batch 181/400 - Loss: 0.5765\n",
      "Batch 191/400 - Loss: 0.3410\n",
      "Batch 201/400 - Loss: 0.3293\n",
      "Batch 211/400 - Loss: 0.6141\n",
      "Batch 221/400 - Loss: 0.1828\n",
      "Batch 231/400 - Loss: 0.5275\n",
      "Batch 241/400 - Loss: 0.3511\n",
      "Batch 251/400 - Loss: 0.3923\n",
      "Batch 261/400 - Loss: 0.6509\n",
      "Batch 271/400 - Loss: 0.3011\n",
      "Batch 281/400 - Loss: 0.1792\n",
      "Batch 291/400 - Loss: 0.3618\n",
      "Batch 301/400 - Loss: 0.4641\n",
      "Batch 311/400 - Loss: 0.7476\n",
      "Batch 321/400 - Loss: 0.2615\n",
      "Batch 331/400 - Loss: 0.4741\n",
      "Batch 341/400 - Loss: 0.5326\n",
      "Batch 351/400 - Loss: 0.4484\n",
      "Batch 361/400 - Loss: 0.7949\n",
      "Batch 371/400 - Loss: 0.3000\n",
      "Batch 381/400 - Loss: 0.6862\n",
      "Batch 391/400 - Loss: 0.6645\n",
      "Epoch [7/10], Loss: 0.5228\n",
      "Validation Batch 1/100 - Loss: 0.6158\n",
      "Validation Batch 6/100 - Loss: 0.7535\n",
      "Validation Batch 11/100 - Loss: 0.8653\n",
      "Validation Batch 16/100 - Loss: 1.1839\n",
      "Validation Batch 21/100 - Loss: 0.3447\n",
      "Validation Batch 26/100 - Loss: 0.2573\n",
      "Validation Batch 31/100 - Loss: 0.0466\n",
      "Validation Batch 36/100 - Loss: 0.2412\n",
      "Validation Batch 41/100 - Loss: 0.4130\n",
      "Validation Batch 46/100 - Loss: 0.0384\n",
      "Validation Batch 51/100 - Loss: 0.7211\n",
      "Validation Batch 56/100 - Loss: 0.5858\n",
      "Validation Batch 61/100 - Loss: 0.4386\n",
      "Validation Batch 66/100 - Loss: 0.3973\n",
      "Validation Batch 71/100 - Loss: 0.4275\n",
      "Validation Batch 76/100 - Loss: 0.9784\n",
      "Validation Batch 81/100 - Loss: 0.9575\n",
      "Validation Batch 86/100 - Loss: 0.6077\n",
      "Validation Batch 91/100 - Loss: 0.5824\n",
      "Validation Batch 96/100 - Loss: 1.0732\n",
      "Validation Loss: 0.5655, Validation Accuracy: 78.75%\n",
      "Epoch 8/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.5356\n",
      "Batch 11/400 - Loss: 0.4840\n",
      "Batch 21/400 - Loss: 0.3929\n",
      "Batch 31/400 - Loss: 0.3731\n",
      "Batch 41/400 - Loss: 0.3940\n",
      "Batch 51/400 - Loss: 0.5517\n",
      "Batch 61/400 - Loss: 0.2328\n",
      "Batch 71/400 - Loss: 0.3814\n",
      "Batch 81/400 - Loss: 0.4073\n",
      "Batch 91/400 - Loss: 0.5390\n",
      "Batch 101/400 - Loss: 0.9267\n",
      "Batch 111/400 - Loss: 0.4115\n",
      "Batch 121/400 - Loss: 0.4608\n",
      "Batch 131/400 - Loss: 0.3418\n",
      "Batch 141/400 - Loss: 0.4916\n",
      "Batch 151/400 - Loss: 0.5592\n",
      "Batch 161/400 - Loss: 0.5436\n",
      "Batch 171/400 - Loss: 0.2605\n",
      "Batch 181/400 - Loss: 0.3022\n",
      "Batch 191/400 - Loss: 0.4068\n",
      "Batch 201/400 - Loss: 0.3936\n",
      "Batch 211/400 - Loss: 0.4984\n",
      "Batch 221/400 - Loss: 0.6392\n",
      "Batch 231/400 - Loss: 0.3704\n",
      "Batch 241/400 - Loss: 0.3836\n",
      "Batch 251/400 - Loss: 0.4049\n",
      "Batch 261/400 - Loss: 0.2768\n",
      "Batch 271/400 - Loss: 0.5235\n",
      "Batch 281/400 - Loss: 0.4334\n",
      "Batch 291/400 - Loss: 0.5677\n",
      "Batch 301/400 - Loss: 0.6511\n",
      "Batch 311/400 - Loss: 0.3916\n",
      "Batch 321/400 - Loss: 0.5251\n",
      "Batch 331/400 - Loss: 0.6105\n",
      "Batch 341/400 - Loss: 0.2864\n",
      "Batch 351/400 - Loss: 0.4645\n",
      "Batch 361/400 - Loss: 0.6446\n",
      "Batch 371/400 - Loss: 0.4722\n",
      "Batch 381/400 - Loss: 0.4036\n",
      "Batch 391/400 - Loss: 0.4245\n",
      "Epoch [8/10], Loss: 0.4723\n",
      "Validation Batch 1/100 - Loss: 1.9775\n",
      "Validation Batch 6/100 - Loss: 2.0533\n",
      "Validation Batch 11/100 - Loss: 1.9315\n",
      "Validation Batch 16/100 - Loss: 2.2723\n",
      "Validation Batch 21/100 - Loss: 1.0595\n",
      "Validation Batch 26/100 - Loss: 0.2469\n",
      "Validation Batch 31/100 - Loss: 0.0326\n",
      "Validation Batch 36/100 - Loss: 0.4621\n",
      "Validation Batch 41/100 - Loss: 0.4482\n",
      "Validation Batch 46/100 - Loss: 0.1505\n",
      "Validation Batch 51/100 - Loss: 0.2076\n",
      "Validation Batch 56/100 - Loss: 0.0829\n",
      "Validation Batch 61/100 - Loss: 0.1147\n",
      "Validation Batch 66/100 - Loss: 0.0570\n",
      "Validation Batch 71/100 - Loss: 0.1026\n",
      "Validation Batch 76/100 - Loss: 1.1401\n",
      "Validation Batch 81/100 - Loss: 0.8818\n",
      "Validation Batch 86/100 - Loss: 0.4866\n",
      "Validation Batch 91/100 - Loss: 0.6375\n",
      "Validation Batch 96/100 - Loss: 0.7488\n",
      "Validation Loss: 0.7809, Validation Accuracy: 74.69%\n",
      "Epoch 9/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.3761\n",
      "Batch 11/400 - Loss: 0.2703\n",
      "Batch 21/400 - Loss: 0.3126\n",
      "Batch 31/400 - Loss: 0.3952\n",
      "Batch 41/400 - Loss: 0.6241\n",
      "Batch 51/400 - Loss: 0.5173\n",
      "Batch 61/400 - Loss: 1.0615\n",
      "Batch 71/400 - Loss: 0.2023\n",
      "Batch 81/400 - Loss: 0.4075\n",
      "Batch 91/400 - Loss: 0.2453\n",
      "Batch 101/400 - Loss: 0.2759\n",
      "Batch 111/400 - Loss: 0.5445\n",
      "Batch 121/400 - Loss: 0.4005\n",
      "Batch 131/400 - Loss: 0.1564\n",
      "Batch 141/400 - Loss: 0.3357\n",
      "Batch 151/400 - Loss: 0.2600\n",
      "Batch 161/400 - Loss: 0.5496\n",
      "Batch 171/400 - Loss: 0.3291\n",
      "Batch 181/400 - Loss: 0.5422\n",
      "Batch 191/400 - Loss: 0.2956\n",
      "Batch 201/400 - Loss: 0.2635\n",
      "Batch 211/400 - Loss: 0.3980\n",
      "Batch 221/400 - Loss: 0.1671\n",
      "Batch 231/400 - Loss: 0.3861\n",
      "Batch 241/400 - Loss: 0.2533\n",
      "Batch 251/400 - Loss: 0.3358\n",
      "Batch 261/400 - Loss: 0.3806\n",
      "Batch 271/400 - Loss: 0.2553\n",
      "Batch 281/400 - Loss: 0.4430\n",
      "Batch 291/400 - Loss: 0.6599\n",
      "Batch 301/400 - Loss: 0.2784\n",
      "Batch 311/400 - Loss: 0.2861\n",
      "Batch 321/400 - Loss: 0.1316\n",
      "Batch 331/400 - Loss: 0.5516\n",
      "Batch 341/400 - Loss: 0.2619\n",
      "Batch 351/400 - Loss: 0.3784\n",
      "Batch 361/400 - Loss: 0.6100\n",
      "Batch 371/400 - Loss: 0.3096\n",
      "Batch 381/400 - Loss: 0.3578\n",
      "Batch 391/400 - Loss: 0.3843\n",
      "Epoch [9/10], Loss: 0.4228\n",
      "Validation Batch 1/100 - Loss: 0.3386\n",
      "Validation Batch 6/100 - Loss: 0.6027\n",
      "Validation Batch 11/100 - Loss: 0.7554\n",
      "Validation Batch 16/100 - Loss: 1.0331\n",
      "Validation Batch 21/100 - Loss: 0.2290\n",
      "Validation Batch 26/100 - Loss: 0.3852\n",
      "Validation Batch 31/100 - Loss: 0.0768\n",
      "Validation Batch 36/100 - Loss: 0.2990\n",
      "Validation Batch 41/100 - Loss: 0.4813\n",
      "Validation Batch 46/100 - Loss: 0.0560\n",
      "Validation Batch 51/100 - Loss: 0.2820\n",
      "Validation Batch 56/100 - Loss: 0.3340\n",
      "Validation Batch 61/100 - Loss: 0.2322\n",
      "Validation Batch 66/100 - Loss: 0.1599\n",
      "Validation Batch 71/100 - Loss: 0.2963\n",
      "Validation Batch 76/100 - Loss: 1.0686\n",
      "Validation Batch 81/100 - Loss: 0.9290\n",
      "Validation Batch 86/100 - Loss: 0.5970\n",
      "Validation Batch 91/100 - Loss: 0.6761\n",
      "Validation Batch 96/100 - Loss: 1.1084\n",
      "Validation Loss: 0.5049, Validation Accuracy: 81.25%\n",
      "Epoch 10/10\n",
      "------------------------------\n",
      "Batch 1/400 - Loss: 0.4752\n",
      "Batch 11/400 - Loss: 0.2470\n",
      "Batch 21/400 - Loss: 0.3010\n",
      "Batch 31/400 - Loss: 0.3724\n",
      "Batch 41/400 - Loss: 0.3673\n",
      "Batch 51/400 - Loss: 0.1441\n",
      "Batch 61/400 - Loss: 0.4820\n",
      "Batch 71/400 - Loss: 0.3910\n",
      "Batch 81/400 - Loss: 0.1059\n",
      "Batch 91/400 - Loss: 0.8995\n",
      "Batch 101/400 - Loss: 0.1544\n",
      "Batch 111/400 - Loss: 0.3000\n",
      "Batch 121/400 - Loss: 0.8801\n",
      "Batch 131/400 - Loss: 0.1161\n",
      "Batch 141/400 - Loss: 0.2401\n",
      "Batch 151/400 - Loss: 0.2077\n",
      "Batch 161/400 - Loss: 0.3048\n",
      "Batch 171/400 - Loss: 0.1781\n",
      "Batch 181/400 - Loss: 0.2773\n",
      "Batch 191/400 - Loss: 0.8414\n",
      "Batch 201/400 - Loss: 0.2410\n",
      "Batch 211/400 - Loss: 0.1130\n",
      "Batch 221/400 - Loss: 0.2106\n",
      "Batch 231/400 - Loss: 0.4351\n",
      "Batch 241/400 - Loss: 0.1889\n",
      "Batch 251/400 - Loss: 0.2319\n",
      "Batch 261/400 - Loss: 0.1367\n",
      "Batch 271/400 - Loss: 0.4388\n",
      "Batch 281/400 - Loss: 0.1474\n",
      "Batch 291/400 - Loss: 0.1022\n",
      "Batch 301/400 - Loss: 0.3481\n",
      "Batch 311/400 - Loss: 0.1367\n",
      "Batch 321/400 - Loss: 0.1935\n",
      "Batch 331/400 - Loss: 0.5420\n",
      "Batch 341/400 - Loss: 0.2390\n",
      "Batch 351/400 - Loss: 0.3099\n",
      "Batch 361/400 - Loss: 0.1694\n",
      "Batch 371/400 - Loss: 0.3421\n",
      "Batch 381/400 - Loss: 0.2653\n",
      "Batch 391/400 - Loss: 0.1922\n",
      "Epoch [10/10], Loss: 0.3661\n",
      "Validation Batch 1/100 - Loss: 0.5040\n",
      "Validation Batch 6/100 - Loss: 0.8884\n",
      "Validation Batch 11/100 - Loss: 1.3250\n",
      "Validation Batch 16/100 - Loss: 1.2792\n",
      "Validation Batch 21/100 - Loss: 0.3945\n",
      "Validation Batch 26/100 - Loss: 0.1973\n",
      "Validation Batch 31/100 - Loss: 0.0388\n",
      "Validation Batch 36/100 - Loss: 0.1646\n",
      "Validation Batch 41/100 - Loss: 0.3478\n",
      "Validation Batch 46/100 - Loss: 0.0291\n",
      "Validation Batch 51/100 - Loss: 0.3964\n",
      "Validation Batch 56/100 - Loss: 0.2492\n",
      "Validation Batch 61/100 - Loss: 0.1493\n",
      "Validation Batch 66/100 - Loss: 0.1802\n",
      "Validation Batch 71/100 - Loss: 0.4523\n",
      "Validation Batch 76/100 - Loss: 1.1421\n",
      "Validation Batch 81/100 - Loss: 0.4526\n",
      "Validation Batch 86/100 - Loss: 0.2286\n",
      "Validation Batch 91/100 - Loss: 0.4439\n",
      "Validation Batch 96/100 - Loss: 0.8823\n",
      "Validation Loss: 0.4886, Validation Accuracy: 83.31%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "verbose = True  # Set to True for detailed output\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Print epoch header\n",
    "    if verbose:\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        print('-' * 30)\n",
    "        \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Verbose output for each batch\n",
    "        if verbose and batch_idx % 10 == 0:  # Display every 10 batches\n",
    "            print(f'Batch {batch_idx + 1}/{len(train_loader)} - Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(validation_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Verbose output for each validation batch\n",
    "            if verbose and batch_idx % 5 == 0:  # Display every 5 validation batches\n",
    "                print(f'Validation Batch {batch_idx + 1}/{len(validation_loader)} - Loss: {loss.item():.4f}')\n",
    "    \n",
    "    val_loss = running_val_loss / len(validation_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "print('Training completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Cody\\Desktop\\Projects\\Mr-Beans\\notebook\\exploration\\beans\\models\\type_cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Define the path where you want to save the model\n",
    "model_save_path = 'C:\\\\Users\\\\Cody\\\\Desktop\\\\Projects\\\\Mr-Beans\\\\notebook\\\\exploration\\\\beans\\\\models\\\\type_cnn_model.pth'\n",
    "\n",
    "# Save the model's state_dict after training is completed\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(f'Model saved to {model_save_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
